{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   make  address   all   3d   our  over  remove  internet  order  mail  ...  \\\n",
      "0  0.00     0.00  0.29  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "1  0.46     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "2  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "3  0.33     0.44  0.37  0.0  0.14  0.11    0.00      0.07   0.97  1.16  ...   \n",
      "4  0.00     2.08  0.00  0.0  3.12  0.00    1.04      0.00   0.00  0.00  ...   \n",
      "\n",
      "   semicol  paren  bracket   bang  dollar  pound  cap_avg  cap_long  \\\n",
      "0    0.000  0.178      0.0  0.044   0.000   0.00    1.666        10   \n",
      "1    0.000  0.125      0.0  0.000   0.000   0.00    1.510        10   \n",
      "2    0.000  0.000      0.0  0.000   0.000   0.00    1.718        11   \n",
      "3    0.006  0.159      0.0  0.069   0.221   0.11    3.426        72   \n",
      "4    0.000  0.000      0.0  0.263   0.000   0.00    1.428         4   \n",
      "\n",
      "   cap_total  Class  \n",
      "0        180    ham  \n",
      "1         74    ham  \n",
      "2         55    ham  \n",
      "3        819   spam  \n",
      "4         20   spam  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "file_path = 'spam.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['Class'] = label_encoder.fit_transform(data['Class'])\n",
    "\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "X_train_initial, X_test_initial, y_train_initial, y_test_initial = X[:1000], X[1000:], y[:1000], y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learner = DecisionTreeClassifier(max_depth=1, random_state=42)\n",
    "adaboost_clf = AdaBoostClassifier(estimator=base_learner, n_estimators=50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Split (1000/3601) Accuracy: 0.9197445154123854\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2049  133]\n",
      " [ 156 1263]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      2182\n",
      "           1       0.90      0.89      0.90      1419\n",
      "\n",
      "    accuracy                           0.92      3601\n",
      "   macro avg       0.92      0.91      0.92      3601\n",
      "weighted avg       0.92      0.92      0.92      3601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adaboost_clf.fit(X_train_initial, y_train_initial)\n",
    "\n",
    "y_pred_initial = adaboost_clf.predict(X_test_initial)\n",
    "\n",
    "print(\"Initial Split (1000/3601) Accuracy:\", accuracy_score(y_test_initial, y_pred_initial))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_initial, y_pred_initial))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_initial, y_pred_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split 50-50%:\n",
      "Accuracy: 0.9317687961755758\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1308   93]\n",
      " [  64  836]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.94\n",
      "  Class 1:\n",
      "    Precision: 0.90\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.91\n",
      "  Class macro avg:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n",
      "  Class weighted avg:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n",
      "\n",
      "Split 60-40%:\n",
      "Accuracy: 0.9359043997827268\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1060   74]\n",
      " [  44  663]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.96\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.95\n",
      "  Class 1:\n",
      "    Precision: 0.90\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.92\n",
      "  Class macro avg:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.93\n",
      "  Class weighted avg:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n",
      "\n",
      "Split 70-30%:\n",
      "Accuracy: 0.9283128167994207\n",
      "\n",
      "Confusion Matrix:\n",
      " [[776  61]\n",
      " [ 38 506]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.94\n",
      "  Class 1:\n",
      "    Precision: 0.89\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.91\n",
      "  Class macro avg:\n",
      "    Precision: 0.92\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n",
      "  Class weighted avg:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n",
      "\n",
      "Split 80-19%:\n",
      "Accuracy: 0.9261672095548317\n",
      "\n",
      "Confusion Matrix:\n",
      " [[522  33]\n",
      " [ 35 331]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n",
      "  Class 1:\n",
      "    Precision: 0.91\n",
      "    Recall: 0.90\n",
      "    F1-score: 0.91\n",
      "  Class macro avg:\n",
      "    Precision: 0.92\n",
      "    Recall: 0.92\n",
      "    F1-score: 0.92\n",
      "  Class weighted avg:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n"
     ]
    }
   ],
   "source": [
    "splits = [0.5, 0.6, 0.7, 0.8]\n",
    "results = {}\n",
    "\n",
    "for split in splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split, random_state=42)\n",
    "\n",
    "    adaboost_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = adaboost_clf.predict(X_test)\n",
    "\n",
    "    results[split] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Classification Report': classification_report(y_test, y_pred, output_dict=True),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "s\n",
    "for split, metrics in results.items():\n",
    "    print(f\"\\nSplit {int(split*100)}-{int((1-split)*100)}%:\")\n",
    "    print(\"Accuracy:\", metrics['Accuracy'])\n",
    "    print(\"\\nConfusion Matrix:\\n\", metrics['Confusion Matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, report in metrics['Classification Report'].items():\n",
    "        if isinstance(report, dict):\n",
    "            print(f\"  Class {label}:\")\n",
    "            print(f\"    Precision: {report['precision']:.2f}\")\n",
    "            print(f\"    Recall: {report['recall']:.2f}\")\n",
    "            print(f\"    F1-score: {report['f1-score']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
