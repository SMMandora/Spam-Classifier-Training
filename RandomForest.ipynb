{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   make  address   all   3d   our  over  remove  internet  order  mail  ...  \\\n",
      "0  0.00     0.00  0.29  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "1  0.46     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "2  0.00     0.00  0.00  0.0  0.00  0.00    0.00      0.00   0.00  0.00  ...   \n",
      "3  0.33     0.44  0.37  0.0  0.14  0.11    0.00      0.07   0.97  1.16  ...   \n",
      "4  0.00     2.08  0.00  0.0  3.12  0.00    1.04      0.00   0.00  0.00  ...   \n",
      "\n",
      "   semicol  paren  bracket   bang  dollar  pound  cap_avg  cap_long  \\\n",
      "0    0.000  0.178      0.0  0.044   0.000   0.00    1.666        10   \n",
      "1    0.000  0.125      0.0  0.000   0.000   0.00    1.510        10   \n",
      "2    0.000  0.000      0.0  0.000   0.000   0.00    1.718        11   \n",
      "3    0.006  0.159      0.0  0.069   0.221   0.11    3.426        72   \n",
      "4    0.000  0.000      0.0  0.263   0.000   0.00    1.428         4   \n",
      "\n",
      "   cap_total  Class  \n",
      "0        180    ham  \n",
      "1         74    ham  \n",
      "2         55    ham  \n",
      "3        819   spam  \n",
      "4         20   spam  \n",
      "\n",
      "[5 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "file_path = 'spam.csv'\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['Class'] = label_encoder.fit_transform(data['Class'])\n",
    "\n",
    "X = data.drop(columns=['Class'])\n",
    "y = data['Class']\n",
    "\n",
    "X_train_initial, X_test_initial, y_train_initial, y_test_initial = X[:1000], X[1000:], y[:1000], y[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Split (1000/3601) Accuracy: 0.9350180505415162\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2103   79]\n",
      " [ 155 1264]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      2182\n",
      "           1       0.94      0.89      0.92      1419\n",
      "\n",
      "    accuracy                           0.94      3601\n",
      "   macro avg       0.94      0.93      0.93      3601\n",
      "weighted avg       0.94      0.94      0.93      3601\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_clf.fit(X_train_initial, y_train_initial)\n",
    "\n",
    "y_pred_initial = random_forest_clf.predict(X_test_initial)\n",
    "\n",
    "print(\"Initial Split (1000/3601) Accuracy:\", accuracy_score(y_test_initial, y_pred_initial))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test_initial, y_pred_initial))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_initial, y_pred_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Split 50-50%:\n",
      "Accuracy: 0.9500217296827467\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1350   51]\n",
      " [  64  836]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.96\n",
      "    F1-score: 0.96\n",
      "  Class 1:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.94\n",
      "  Class macro avg:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.95\n",
      "    F1-score: 0.95\n",
      "  Class weighted avg:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.95\n",
      "    F1-score: 0.95\n",
      "\n",
      "Split 60-40%:\n",
      "Accuracy: 0.9505703422053232\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1092   42]\n",
      " [  49  658]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.96\n",
      "    Recall: 0.96\n",
      "    F1-score: 0.96\n",
      "  Class 1:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.94\n",
      "  Class macro avg:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.95\n",
      "    F1-score: 0.95\n",
      "  Class weighted avg:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.95\n",
      "    F1-score: 0.95\n",
      "\n",
      "Split 70-30%:\n",
      "Accuracy: 0.943519188993483\n",
      "\n",
      "Confusion Matrix:\n",
      " [[802  35]\n",
      " [ 43 501]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.96\n",
      "    F1-score: 0.95\n",
      "  Class 1:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.92\n",
      "    F1-score: 0.93\n",
      "  Class macro avg:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n",
      "  Class weighted avg:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n",
      "\n",
      "Split 80-19%:\n",
      "Accuracy: 0.9435396308360477\n",
      "\n",
      "Confusion Matrix:\n",
      " [[529  26]\n",
      " [ 26 340]]\n",
      "\n",
      "Classification Report:\n",
      "  Class 0:\n",
      "    Precision: 0.95\n",
      "    Recall: 0.95\n",
      "    F1-score: 0.95\n",
      "  Class 1:\n",
      "    Precision: 0.93\n",
      "    Recall: 0.93\n",
      "    F1-score: 0.93\n",
      "  Class macro avg:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n",
      "  Class weighted avg:\n",
      "    Precision: 0.94\n",
      "    Recall: 0.94\n",
      "    F1-score: 0.94\n"
     ]
    }
   ],
   "source": [
    "splits = [0.5, 0.6, 0.7, 0.8]\n",
    "results = {}\n",
    "\n",
    "for split in splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-split, random_state=42)\n",
    "\n",
    "    random_forest_clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = random_forest_clf.predict(X_test)\n",
    "\n",
    "    results[split] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Classification Report': classification_report(y_test, y_pred, output_dict=True),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "for split, metrics in results.items():\n",
    "    print(f\"\\nSplit {int(split*100)}-{int((1-split)*100)}%:\")\n",
    "    print(\"Accuracy:\", metrics['Accuracy'])\n",
    "    print(\"\\nConfusion Matrix:\\n\", metrics['Confusion Matrix'])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    for label, report in metrics['Classification Report'].items():\n",
    "        if isinstance(report, dict):\n",
    "            print(f\"  Class {label}:\")\n",
    "            print(f\"    Precision: {report['precision']:.2f}\")\n",
    "            print(f\"    Recall: {report['recall']:.2f}\")\n",
    "            print(f\"    F1-score: {report['f1-score']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
